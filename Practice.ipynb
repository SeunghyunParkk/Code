{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(4,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7841, 0.2717],\n",
       "        [0.3353, 0.8528],\n",
       "        [0.6124, 0.8460],\n",
       "        [0.0621, 0.8897]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(4,2, dtype = torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 2.3000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3,2.3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(2,4, dtype = torch.double)\n",
    "x\n",
    "# new_ones, new_zeros, new_full (shape 다음에 값을 넣으면 그 값으로 채워짐), new_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2177, 1.4166, 0.4928, 0.4677],\n",
       "        [0.8268, 0.0197, 2.6270, 1.4591]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존의 텐서 모양이랑 같은걸로 만들어라\n",
    "x = torch.randn_like(x, dtype = torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size()\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([1,2,3])\n",
    "print(ft)\n",
    "print(ft.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int16)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.short())\n",
    "print(ft.int())\n",
    "print(ft.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "it = torch.IntTensor([1,2,3])\n",
    "print(it)\n",
    "print(it.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(it.float())\n",
    "print(it.double())\n",
    "print(it.half())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA Tensors\n",
    "\n",
    ".to 메소드를 사용하여 텐서를 어떠한 장치로 옮길수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4220])\n",
      "0.4219599962234497\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available()) # MPS 장치가 사용 가능한지 확인합니다. True여야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([1.], device='mps:0')\n",
      "tensor([0.4220], device='mps:0')\n",
      "tensor([1.4220], device='mps:0')\n",
      "tensor([1.4220])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "y = torch.ones_like(x,device = device)\n",
    "print(y)\n",
    "x = x.to(device)\n",
    "print(x)\n",
    "z = x+y\n",
    "print(z)\n",
    "print(z.to('cpu', torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다차원 텐서 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# 0d tensor\n",
    "t0 = torch.tensor(0)\n",
    "print(t0.ndim)\n",
    "print(t0.shape)\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1D tensor\n",
    "t1 = torch.tensor([1,2,3])\n",
    "print(t1.ndim)\n",
    "print(t1.shape)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# 2D tensor\n",
    "t2 = torch.tensor([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]])\n",
    "print(t2.ndim)\n",
    "print(t2.shape)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "# 3D tensor\n",
    "t3 = torch.tensor([[[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]],\n",
    "                   [[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]],\n",
    "                   [[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]]])\n",
    "print(t3.ndim)\n",
    "print(t3.shape)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3363, -0.8073]])\n",
      "tensor([[0.3363, 0.8073]])\n",
      "tensor([[-0., -0.]])\n",
      "tensor([[-1., -1.]])\n",
      "tensor([[-0.3363, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a = torch.rand(1,2) * 2 - 1\n",
    "print(a)\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3363, -0.8073]])\n",
      "tensor(-0.8073)\n",
      "tensor(-0.3363)\n",
      "tensor(-0.5718)\n",
      "tensor(0.3330)\n",
      "tensor(0.2715)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(torch.min(a))\n",
    "print(torch.max(a))\n",
    "print(torch.mean(a))\n",
    "print(torch.std(a))\n",
    "print(torch.prod(a))\n",
    "print(torch.unique(torch.tensor([1,2,3,1,2,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2988, 0.8890],\n",
      "        [0.8963, 0.3705]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8963, 0.8890]),\n",
      "indices=tensor([1, 0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8890, 0.8963]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# max 와 min은 dim 인자를 줄 경우 argmax와 argmin도 함께 리턴\n",
    "# argmax: 최대값을 가진 인덱스\n",
    "# argmin: 최소값을 가진 인덱스\n",
    "# dim = 0 은 column\n",
    "# dim = 1 은 row\n",
    "x = torch.rand(2,2)\n",
    "print(x)\n",
    "print(x.max(dim=0))\n",
    "print(x.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2988, 0.8890],\n",
      "        [0.8963, 0.3705]])\n",
      "torch.return_types.min(\n",
      "values=tensor([0.2988, 0.3705]),\n",
      "indices=tensor([0, 1]))\n",
      "torch.return_types.min(\n",
      "values=tensor([0.2988, 0.3705]),\n",
      "indices=tensor([0, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.min(dim=0))\n",
    "print(x.min(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[0.7083, 0.8726],\n",
      "        [0.9300, 0.1533]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "print(x)\n",
    "y = torch.rand(2,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.add: 덧셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mk/3rm9f8jj0_54616_xx1g__n00000gn/T/ipykernel_15284/450674821.py:3: UserWarning: An output with one or more elements was resized since it had shape [2, 4], which does not match the required output shape [2, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:35.)\n",
      "  torch.add(x,y, out = result)\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2,4)\n",
    "print(result)\n",
    "torch.add(x,y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "in-place 방식\n",
    "```\n",
    "* in-place 방식으로 텐서의 값을 변경하는 연산 뒤에서는 _\"가 붙음\n",
    "* ``` x.copy_(y), x.t_(x) ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[0.7083, 0.8726],\n",
      "        [0.9300, 0.1533]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n",
      "tensor([[-0.7083, -0.8726],\n",
      "        [-0.9300, -0.1533]])\n",
      "tensor([[-0.7083, -0.8726],\n",
      "        [-0.9300, -0.1533]])\n",
      "tensor([[-0.7083, -0.8726],\n",
      "        [-0.9300, -0.1533]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x - y)\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n",
      "tensor([[1.2958, 1.2409],\n",
      "        [0.3338, 0.5077]])\n",
      "tensor([[1.2958, 1.2409],\n",
      "        [0.3338, 0.5077]])\n",
      "tensor([[1.2958, 1.2409],\n",
      "        [0.3338, 0.5077]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x * y)\n",
    "print(torch.mul(x,y))\n",
    "print(x.mul(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n",
      "tensor([[0.5419, 0.4655],\n",
      "        [0.2293, 0.8068]])\n",
      "tensor([[0.5419, 0.4655],\n",
      "        [0.2293, 0.8068]])\n",
      "tensor([[0.5419, 0.4655],\n",
      "        [0.2293, 0.8068]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x / y)\n",
    "print(torch.div(x,y))\n",
    "print(x.div(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8380, 0.7601],\n",
      "        [0.2766, 0.6400]])\n",
      "tensor([[1.5463, 1.6327],\n",
      "        [1.2066, 0.7932]])\n",
      "tensor([[2.2129, 1.9711],\n",
      "        [1.2000, 0.9593]])\n",
      "tensor([[2.2129, 1.9711],\n",
      "        [1.2000, 0.9593]])\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.8879, -0.4599],\n",
      "        [-0.4599,  0.8879]]),\n",
      "S=tensor([3.3372, 0.0726]),\n",
      "V=tensor([[-0.7542,  0.6567],\n",
      "        [-0.6567, -0.7542]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.mm: 내적 (dot product)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(torch.matmul(x,y))\n",
    "z = torch.mm(x,y)\n",
    "print(z)\n",
    "print(torch.svd(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 조작 (Manipulations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor([1., 3.])\n",
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2],\n",
    "                 [3,4]])\n",
    "print(x)\n",
    "print(x[0,0])\n",
    "print(x[0,1])\n",
    "print(x[1,0])\n",
    "print(x[1,1])\n",
    "\n",
    "print(x[:,0])\n",
    "print(x[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` view```: 텐서의 크기나 모양을 변경\n",
    "* 기본적으로 변경 전과 후에 텐서 안의 원소 개수가 유지되어야함\n",
    "* -1로 설정되면 계산을 통해 해당 크기값을 유추\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3698, -1.9336, -0.1553, -0.2075,  0.5781],\n",
      "        [-0.3389, -0.6679,  0.1736,  0.0565,  0.2302],\n",
      "        [ 0.4520, -1.8762,  0.1671,  0.4431, -0.9889],\n",
      "        [-0.7728,  0.0598,  0.3785,  1.4025,  1.0198]])\n",
      "tensor([-0.3698, -1.9336, -0.1553, -0.2075,  0.5781, -0.3389, -0.6679,  0.1736,\n",
      "         0.0565,  0.2302,  0.4520, -1.8762,  0.1671,  0.4431, -0.9889, -0.7728,\n",
      "         0.0598,  0.3785,  1.4025,  1.0198])\n",
      "tensor([[-0.3698, -1.9336],\n",
      "        [-0.1553, -0.2075],\n",
      "        [ 0.5781, -0.3389],\n",
      "        [-0.6679,  0.1736],\n",
      "        [ 0.0565,  0.2302],\n",
      "        [ 0.4520, -1.8762],\n",
      "        [ 0.1671,  0.4431],\n",
      "        [-0.9889, -0.7728],\n",
      "        [ 0.0598,  0.3785],\n",
      "        [ 1.4025,  1.0198]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "print(x)\n",
    "y = x.view(20)\n",
    "print(y)\n",
    "z = x.view(10,-1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0231])\n",
      "-0.02310161292552948\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# item: 텐서의 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)\n",
    "# 아이템이 하나 일때만 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2865, 0.1330, 0.6921],\n",
      "         [0.6174, 0.0316, 0.8175],\n",
      "         [0.4251, 0.0159, 0.4145]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# squeeze: 차원을 축소 (제거)\n",
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2865, 0.1330, 0.6921],\n",
      "        [0.6174, 0.0316, 0.8175],\n",
      "        [0.4251, 0.0159, 0.4145]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.squeeze()\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0918, 0.4735, 0.9566],\n",
      "        [0.0020, 0.6181, 0.6006],\n",
      "        [0.9212, 0.0410, 0.6478]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[[0.0918, 0.4735, 0.9566],\n",
      "         [0.0020, 0.6181, 0.6006],\n",
      "         [0.9212, 0.0410, 0.6478]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze: 차원을 증가 (생성)\n",
    "t = torch.rand(3,3)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "tensor = t.unsqueeze(dim = 0)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0918],\n",
      "         [0.4735],\n",
      "         [0.9566]],\n",
      "\n",
      "        [[0.0020],\n",
      "         [0.6181],\n",
      "         [0.6006]],\n",
      "\n",
      "        [[0.9212],\n",
      "         [0.0410],\n",
      "         [0.6478]]])\n",
      "torch.Size([3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim = 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0918, 0.4735, 0.9566]],\n",
      "\n",
      "        [[0.0020, 0.6181, 0.6006]],\n",
      "\n",
      "        [[0.9212, 0.0410, 0.6478]]])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim = 1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4.])\n",
      "tensor([2., 5.])\n",
      "tensor([3., 6.])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# stack: 텐서간 결합\n",
    "x = torch.FloatTensor([1,4])\n",
    "print(x)\n",
    "y = torch.FloatTensor([2,5])\n",
    "print(y)\n",
    "z = torch.FloatTensor([3,6])\n",
    "print(z)\n",
    "\n",
    "print(torch.stack([x,y,z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0995,  0.0329,  1.1276],\n",
      "         [-0.7671,  1.8259,  2.2172],\n",
      "         [-0.0417,  0.9871,  0.8185]]])\n",
      "tensor([[[-0.1623, -0.0196, -0.4343],\n",
      "         [ 0.2518, -0.0243,  0.3980],\n",
      "         [-1.4870,  0.0253, -0.5938]]])\n",
      "tensor([[[ 0.0995,  0.0329,  1.1276],\n",
      "         [-0.7671,  1.8259,  2.2172],\n",
      "         [-0.0417,  0.9871,  0.8185]],\n",
      "\n",
      "        [[-0.1623, -0.0196, -0.4343],\n",
      "         [ 0.2518, -0.0243,  0.3980],\n",
      "         [-1.4870,  0.0253, -0.5938]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# cat: 텐서를 결합\n",
    "# 넘파이의 stack과 유사하지만, 쌓을 dim 존재해야함\n",
    "# 해달 차원을 늘려준 후 결합\n",
    "\n",
    "a = torch.randn(1,3,3)\n",
    "print(a)\n",
    "b = torch.randn(1,3,3)\n",
    "print(b)\n",
    "c = torch.cat((a,b), dim=0)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0995,  0.0329,  1.1276],\n",
      "         [-0.7671,  1.8259,  2.2172],\n",
      "         [-0.0417,  0.9871,  0.8185],\n",
      "         [-0.1623, -0.0196, -0.4343],\n",
      "         [ 0.2518, -0.0243,  0.3980],\n",
      "         [-1.4870,  0.0253, -0.5938]]])\n",
      "torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat((a,b), dim=1)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0995,  0.0329,  1.1276, -0.1623, -0.0196, -0.4343],\n",
      "         [-0.7671,  1.8259,  2.2172,  0.2518, -0.0243,  0.3980],\n",
      "         [-0.0417,  0.9871,  0.8185, -1.4870,  0.0253, -0.5938]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat((a,b), dim=2)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4435, 0.8465, 0.0658, 0.5513, 0.1067, 0.4230],\n",
      "        [0.8089, 0.2242, 0.2853, 0.7421, 0.4301, 0.0955],\n",
      "        [0.4549, 0.3276, 0.6084, 0.2432, 0.2447, 0.4018]])\n",
      "tensor([[0.4435, 0.8465],\n",
      "        [0.8089, 0.2242],\n",
      "        [0.4549, 0.3276]])\n",
      "tensor([[0.0658, 0.5513],\n",
      "        [0.2853, 0.7421],\n",
      "        [0.6084, 0.2432]])\n",
      "tensor([[0.1067, 0.4230],\n",
      "        [0.4301, 0.0955],\n",
      "        [0.2447, 0.4018]])\n"
     ]
    }
   ],
   "source": [
    "# chunk: 텐서를 여러개로 나눌때 사용\n",
    "tensor = torch.rand(3,6)\n",
    "print(tensor)\n",
    "\n",
    "t1, t2, t3 = torch.chunk(tensor, 3, dim = 1)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4435, 0.8465, 0.0658, 0.5513, 0.1067, 0.4230]])\n",
      "tensor([[0.8089, 0.2242, 0.2853, 0.7421, 0.4301, 0.0955]])\n",
      "tensor([[0.4549, 0.3276, 0.6084, 0.2432, 0.2447, 0.4018]])\n"
     ]
    }
   ],
   "source": [
    "t1, t2, t3 = torch.chunk(tensor, 3, dim = 0)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7049, 0.0414, 0.7343, 0.0894, 0.2161, 0.3926],\n",
      "        [0.8293, 0.9111, 0.7108, 0.0106, 0.0970, 0.4035],\n",
      "        [0.0576, 0.7979, 0.5104, 0.5210, 0.9026, 0.6812]])\n",
      "tensor([[0.7049, 0.0414, 0.7343],\n",
      "        [0.8293, 0.9111, 0.7108],\n",
      "        [0.0576, 0.7979, 0.5104]])\n",
      "tensor([[0.0894, 0.2161, 0.3926],\n",
      "        [0.0106, 0.0970, 0.4035],\n",
      "        [0.5210, 0.9026, 0.6812]])\n"
     ]
    }
   ],
   "source": [
    "# split: chunk 와 동일한 기능이지만 조금 다름, 몇개의 라인\n",
    "tensor = torch.rand(3,6)\n",
    "t1, t2 = torch.split(tensor,3,dim=1)\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(7)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "np.add(a,1, out= a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd (자동미분)\n",
    "\n",
    "* `torch.autograd' 패키지는 Tensor의 모든 연산에 대해 자동미분 제공\n",
    "* 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
    "* `backprop`를 위해 미분값을 자동으로 계싼\n",
    "\n",
    "`required_grad` 속성을 True로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
    "기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2023,  2.2239, -3.5101],\n",
      "        [-1.3198,  2.8548, -2.6215],\n",
      "        [ 2.4340, -1.4080,  0.6296]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "a = a *3\n",
    "print(a)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor(47.1841, grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x16d751e80>\n"
     ]
    }
   ],
   "source": [
    "# requires_grad_() 는 기존 텐서의 requires_grad 값을 in-place\n",
    "# grad_fn: 미분값을 계산한 함수에 대한 정보 저장\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# gradient\n",
    "x = torch.ones(3,3, requires_grad = True)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+5\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36., 36., 36.],\n",
      "        [36., 36., 36.],\n",
      "        [36., 36., 36.]], grad_fn=<MulBackward0>) tensor(36., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y\n",
    "out = z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n",
      "tensor([[1.3333, 1.3333, 1.3333],\n",
      "        [1.3333, 1.3333, 1.3333],\n",
      "        [1.3333, 1.3333, 1.3333]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-791.0658, -947.7231, -140.5893], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x *2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y*2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1,1.0,0.0001], dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0960e+02, 4.0960e+03, 4.0960e-01])\n"
     ]
    }
   ],
   "source": [
    "y. backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
